{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Field,Details\n",
        "Job 02:,Create Project on Artificial Intelligence (AI) and Machine Learning (ML)\n",
        "Time:,60 Minutes\n",
        "Unit Covered:,OU-ICT-AIIT-03-L6-V1: Create Project on AI and ML\n",
        "\n",
        "\n",
        "\n",
        "### **Working Procedure/ Steps:**\n",
        "\n",
        "1. Wear the required **Personal Protective Equipment (PPE)** for the job.\n",
        "2. Observe and follow appropriate **occupational health and safety (OHS)** requirements during the demonstration.\n",
        "3. Check Electricity, Peripheral device & Internet Connections to your Computer.\n",
        "4. Start the Computer.\n",
        "5. Check for software errors and troubleshoot problems.\n",
        "6. Collect the resources (Dataset) and materials from your assessor as per the job requirement.\n",
        "7. Create a **Weather Prediction System**.\n",
        "8. Set up the **Python environment** required to create the system.\n",
        "9. Load the weather dataset into the environment.\n",
        "10. Perform initial **data inspection**.\n",
        "11. Define the **ML Problem Statement**.\n",
        "12. Perform **Feature Selection**.\n",
        "13. **Split the dataset** for training and testing.\n",
        "14. Implement a **baseline ML model**.\n",
        "15. Apply **feature scaling**, compare model performance before and after scaling.\n",
        "16. Train other **optimized ML models** (at least 2 Model).\n",
        "17. **Evaluate** Model Performance.\n",
        "18. **Visualize** Model Performance.\n",
        "19. Detect **Overfitting and Underfitting**.\n",
        "20. **Save and deploy** the final model.\n",
        "21. Submit the final output to the competency assessor.\n",
        "22. Shut down the computer and clean your workplace.\n",
        "23. Clean tools, equipment, materials, and work area.\n",
        "\n",
        "\n",
        "Category,Required Items\n",
        "\"Tools, Equipment, and furniture:\",1. Personal Computer – 1 set  2. Ergonomic Chair – 1 Pc\n",
        "Software:,1. Operating software – Windows or Linux  2. Programming and ML Tools:      2.1 Python (version 3.8 or later)      2.2 Jupyter Notebook / JupyterLab      2.3 Integrated Development Environment (IDE): VS Code / PyCharm\n",
        "PPE (Personal Protective Equipment):,1. Rubber sole Shoes/Sandal – 1 pair"
      ],
      "metadata": {
        "id": "J7o_424WWiB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Wear the required Personal Protective Equipment (PPE)\n",
        "\n",
        "Demonstration:\n",
        "\n",
        "Ensure clean workspace\n",
        "\n",
        "No liquid near computer\n",
        "\n",
        "Proper seating & posture\n",
        "\n",
        "Why: Prevents electrical hazards and physical strain."
      ],
      "metadata": {
        "id": "ug2M9ZxoXI1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Follow Occupational Health & Safety (OHS)\n",
        "\n",
        "Actions:\n",
        "\n",
        "Proper cable management\n",
        "\n",
        "Adequate lighting\n",
        "\n",
        "Take breaks\n",
        "\n",
        "Why: Ensures safe and professional working conditions."
      ],
      "metadata": {
        "id": "RdDUqXexXO4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Check Electricity, Peripheral & Internet Connections\n",
        "\n",
        "Check:\n",
        "\n",
        "Power supply\n",
        "\n",
        "Keyboard, mouse\n",
        "\n",
        "Internet connectivity\n",
        "\n",
        "Why: Required for software installation, dataset access, and deployment."
      ],
      "metadata": {
        "id": "pU747V8lXVwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Start the Computer\n",
        "\n",
        "Power on system\n",
        "\n",
        "Login to OS"
      ],
      "metadata": {
        "id": "wOfYTe0oXbIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Check for Software Errors & Troubleshoot\n",
        "\n",
        "Check:\n",
        "\n",
        "Python installed\n",
        "\n",
        "No OS errors"
      ],
      "metadata": {
        "id": "JIwgE7EUXl9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71nKOLT9WU7U"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Collect Resources (Dataset)\n",
        "\n",
        "Dataset:\n",
        "Weather Test Data (provided by assessor)\n",
        "\n",
        "Purpose: Used to train and test the Weather Prediction model."
      ],
      "metadata": {
        "id": "SskNytTVXqAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Create a Weather Prediction System\n",
        "\n",
        "Goal:\n",
        "Predict weather outcome (e.g., Rain / No Rain or Temperature condition) using ML."
      ],
      "metadata": {
        "id": "fRLpdX3pXrRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Set Up Python Environment"
      ],
      "metadata": {
        "id": "9Ay9tT3NX4JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries for development\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import joblib"
      ],
      "metadata": {
        "id": "RzvR6R7XYCmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Load Weather Dataset"
      ],
      "metadata": {
        "id": "2TkCil8rYPw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/sample_data/Job_2_resource_Weather Test Data.csv\")"
      ],
      "metadata": {
        "id": "Pb39MWrNYLft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Perform Initial Data Inspection\n",
        "\n",
        "Why:\n",
        "\n",
        "Understand structure\n",
        "\n",
        "Identify missing values\n",
        "\n",
        "Check data types"
      ],
      "metadata": {
        "id": "CTN5_uO4YaUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "KKQWT_P7YY3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "l5dAFp_-YnJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "HUtpCQa8YoJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "1fpvG7fcYx2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "kBQdXru9c1WT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "u37KjEgTc6f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "p-oFNdgndJ-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select_dtypes(include=\"object\").columns"
      ],
      "metadata": {
        "id": "xDQVOpYDbWzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "2-LQDuOHdmFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=[\"row ID\"], errors=\"ignore\")"
      ],
      "metadata": {
        "id": "RPGCcNfyeLHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select_dtypes(include=\"object\").columns"
      ],
      "metadata": {
        "id": "6j5sdODleQiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "categorical_cols = [\n",
        "    'Location',\n",
        "    'WindGustDir',\n",
        "    'WindDir9am',\n",
        "    'WindDir3pm',\n",
        "    'RainToday'\n",
        "]\n",
        "\n",
        "for col in categorical_cols:\n",
        "    df[col] = le.fit_transform(df[col].astype(str))"
      ],
      "metadata": {
        "id": "JacL7kj0eYRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "6nyTL5ege7A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Define ML Problem Statement\n",
        "\n",
        "Problem Type: Supervised Learning\n",
        "Task: Classification / Regression (based on target column)\n",
        "\n",
        "Example:\n",
        "\n",
        "Predict whether it will rain based on weather conditions."
      ],
      "metadata": {
        "id": "mk39eR3MY6oY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Perform Feature Selection"
      ],
      "metadata": {
        "id": "diaBEAafZcxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(\"RainToday\", axis=1)\n",
        "y = df[\"RainToday\"]"
      ],
      "metadata": {
        "id": "qT1wz8pnY0F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Split Dataset (Train & Test)"
      ],
      "metadata": {
        "id": "-zOZXMhBZkA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "hASPWX5RY_Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Implement Baseline ML Model"
      ],
      "metadata": {
        "id": "Xyn1k1XwZ52X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Identify all columns that are \"object\" type (strings)\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "print(\"Encoding these columns:\", categorical_cols.tolist())\n",
        "\n",
        "# 2. Initialize the Encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# 3. Convert strings to numbers\n",
        "for col in categorical_cols:\n",
        "    X[col] = le.fit_transform(X[col].astype(str))\n",
        "\n",
        "# Now that X contains only numbers, you can safely split and fit\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now Step 14 will work!\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "baseline_model = LogisticRegression(max_iter=1000)\n",
        "baseline_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Baseline Model trained successfully!\")"
      ],
      "metadata": {
        "id": "zQW4BqUtMTzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Initialize the Baseline Model\n",
        "# We set max_iter to 1000 to ensure the solver has enough iterations to converge\n",
        "baseline_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# 2. Train (Fit) the model on the training data\n",
        "# Note: This should be done on the data BEFORE scaling for the baseline comparison\n",
        "baseline_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Make Predictions\n",
        "y_pred_baseline = baseline_model.predict(X_test)\n",
        "\n",
        "# 4. Evaluate Performance\n",
        "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
        "\n",
        "print(f\"Baseline Model Accuracy: {baseline_accuracy:.4f}\")\n",
        "print(\"\\nBaseline Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_baseline))"
      ],
      "metadata": {
        "id": "FdiMmffMaXaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Apply Feature Scaling & Compare"
      ],
      "metadata": {
        "id": "lvAo_KvkfRLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "065_oF5OfE9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Train Optimized ML Models (At Least 2)"
      ],
      "metadata": {
        "id": "j0xL_NSEfX0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "qc7QvZqZfZNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Evaluate Model Performance"
      ],
      "metadata": {
        "id": "8wCKox__fiFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Logistic:\", accuracy_score(y_test, baseline_model.predict(X_test)))\n",
        "print(\"Decision Tree:\", accuracy_score(y_test, dt.predict(X_test)))\n",
        "print(\"Random Forest:\", accuracy_score(y_test, rf.predict(X_test)))"
      ],
      "metadata": {
        "id": "Lt2zJp58fbuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Visualize Model Performance"
      ],
      "metadata": {
        "id": "jNH5Nv0DfrVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = [\"Logistic\", \"Decision Tree\", \"Random Forest\"]\n",
        "accuracy = [0.78, 0.81, 0.85]\n",
        "\n",
        "plt.bar(models, accuracy)\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gdlXpKSJfkle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Detect Overfitting & Underfitting"
      ],
      "metadata": {
        "id": "DAROFZEhgE6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Training accuracy\n",
        "y_train_pred = baseline_model.predict(X_train)\n",
        "train_acc = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "print(\"Training Accuracy:\", train_acc)"
      ],
      "metadata": {
        "id": "tyXL2OqkgJwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing accuracy\n",
        "y_test_pred = baseline_model.predict(X_test)\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Testing Accuracy:\", test_acc)"
      ],
      "metadata": {
        "id": "0D-O__m3NH0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting / Underfitting Detection Logic"
      ],
      "metadata": {
        "id": "fw_ScVOOgb0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if train_acc > 0.90 and test_acc < 0.70:\n",
        "    print(\"⚠️ Model is OVERFITTING\")\n",
        "elif train_acc < 0.70 and test_acc < 0.70:\n",
        "    print(\"⚠️ Model is UNDERFITTING\")\n",
        "else:\n",
        "    print(\"✅ Model is BALANCED / GENERALIZED\")"
      ],
      "metadata": {
        "id": "QToRHeUNgWgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar([\"Training Accuracy\", \"Testing Accuracy\"], [train_acc, test_acc])\n",
        "plt.ylim(0, 1)\n",
        "plt.title(\"Overfitting & Underfitting Detection\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oXRdvq7sge89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Save and Deploy Final Model"
      ],
      "metadata": {
        "id": "dj9x13Ing0cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model and scaler\n",
        "joblib.dump(model, \"weather_model.joblib\")\n",
        "joblib.dump(scaler, \"scaler.joblib\")"
      ],
      "metadata": {
        "id": "bvl9uQlPgoyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment:\n",
        "\n",
        "Can be used in Flask / FastAPI / Desktop app"
      ],
      "metadata": {
        "id": "aH3SheBIhIz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Submit Final Output to Assessor\n",
        "\n",
        "Submit:\n",
        "\n",
        "Dataset\n",
        "\n",
        "Notebook (.ipynb)\n",
        "\n",
        "Model file (.joblib)\n",
        "\n",
        "README.md"
      ],
      "metadata": {
        "id": "JuiULofuhc52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Shut Down Computer\n",
        "\n",
        "Close applications\n",
        "\n",
        "Shutdown OS properly"
      ],
      "metadata": {
        "id": "OBDCS4cyhjlm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Shut Down Computer\n",
        "\n",
        "Close applications\n",
        "\n",
        "Shutdown OS properly"
      ],
      "metadata": {
        "id": "tRq4EToQhnhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Qa7dxgkhHqg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}